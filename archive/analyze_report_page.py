#!/usr/bin/env python3
"""
DART ë³´ê³ ì„œ í˜ì´ì§€ ë¶„ì„ - ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì°¾ê¸°
"""

import requests
from bs4 import BeautifulSoup
import re

def analyze_report_page():
    """DART ë³´ê³ ì„œ í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ì •ë³´ ë¶„ì„"""
    print("ğŸ” DART ë³´ê³ ì„œ í˜ì´ì§€ ë‹¤ìš´ë¡œë“œ ë¶„ì„")
    print("=" * 50)
    
    # ì²« ë²ˆì§¸ ë§í¬ í…ŒìŠ¤íŠ¸
    test_url = "https://dart.fss.or.kr/dsaf001/main.do?rcpNo=20250814003156"
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    })
    
    try:
        print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ URL: {test_url}")
        response = session.get(test_url)
        response.raise_for_status()
        
        print(f"âœ… í˜ì´ì§€ ì ‘ì† ì„±ê³µ (ê¸¸ì´: {len(response.text)})")
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. rcpNo ì¶”ì¶œ (URLì—ì„œ)
        rcp_no_match = re.search(r'rcpNo=(\d+)', test_url)
        rcp_no = rcp_no_match.group(1) if rcp_no_match else None
        print(f"ğŸ“‹ rcpNo: {rcp_no}")
        
        # 2. dcmNo ì°¾ê¸° - ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        print(f"\nğŸ” dcmNo ì°¾ê¸°:")
        
        # ë°©ë²• 1: JavaScript ë³€ìˆ˜ì—ì„œ ì°¾ê¸°
        scripts = soup.find_all('script')
        dcm_no = None
        
        for script in scripts:
            if script.string:
                content = script.string
                # dcmNo ë³€ìˆ˜ ì°¾ê¸°
                dcm_match = re.search(r'dcmNo\s*[=:]\s*["\']?(\d+)["\']?', content, re.IGNORECASE)
                if dcm_match:
                    dcm_no = dcm_match.group(1)
                    print(f"  JavaScript ë³€ìˆ˜ì—ì„œ ë°œê²¬: {dcm_no}")
                    break
                
                # openPdfDownload í•¨ìˆ˜ í˜¸ì¶œ ì°¾ê¸°
                pdf_match = re.search(r'openPdfDownload\s*\(\s*["\']?(\d+)["\']?\s*,\s*["\']?(\d+)["\']?\s*\)', content)
                if pdf_match:
                    rcp_param = pdf_match.group(1)
                    dcm_param = pdf_match.group(2)
                    print(f"  openPdfDownload í˜¸ì¶œì—ì„œ ë°œê²¬: rcpNo={rcp_param}, dcmNo={dcm_param}")
                    if not dcm_no:
                        dcm_no = dcm_param
                    break
        
        # ë°©ë²• 2: HTML ì†ì„±ì—ì„œ ì°¾ê¸°
        if not dcm_no:
            # data-* ì†ì„±ì´ë‚˜ value ì†ì„±ì—ì„œ ì°¾ê¸°
            elements_with_dcm = soup.find_all(attrs={'data-dcm-no': True})
            if elements_with_dcm:
                dcm_no = elements_with_dcm[0]['data-dcm-no']
                print(f"  HTML data-dcm-no ì†ì„±ì—ì„œ ë°œê²¬: {dcm_no}")
        
        # ë°©ë²• 3: ìˆ¨ê²¨ì§„ input í•„ë“œì—ì„œ ì°¾ê¸°
        if not dcm_no:
            hidden_inputs = soup.find_all('input', {'type': 'hidden'})
            for inp in hidden_inputs:
                name = inp.get('name', '').lower()
                if 'dcm' in name or 'doc' in name:
                    value = inp.get('value', '')
                    if value and value.isdigit():
                        dcm_no = value
                        print(f"  ìˆ¨ê²¨ì§„ input[{inp.get('name')}]ì—ì„œ ë°œê²¬: {dcm_no}")
                        break
        
        # ë°©ë²• 4: ë‹¤ìš´ë¡œë“œ ë²„íŠ¼/ë§í¬ì—ì„œ ì°¾ê¸°
        if not dcm_no:
            # ë‹¤ìš´ë¡œë“œ ê´€ë ¨ ë²„íŠ¼ì´ë‚˜ ë§í¬ ì°¾ê¸°
            download_elements = soup.find_all(['a', 'button'], 
                string=re.compile(r'ë‹¤ìš´ë¡œë“œ|download|PDF', re.IGNORECASE))
            
            for elem in download_elements:
                onclick = elem.get('onclick', '')
                href = elem.get('href', '')
                
                # onclickì—ì„œ dcmNo ì¶”ì¶œ
                if onclick:
                    dcm_match = re.search(r'(\d{8,})', onclick)
                    if dcm_match:
                        dcm_no = dcm_match.group(1)
                        print(f"  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ onclickì—ì„œ ë°œê²¬: {dcm_no}")
                        print(f"  ì „ì²´ onclick: {onclick}")
                        break
                
                # hrefì—ì„œ dcmNo ì¶”ì¶œ
                if href and 'dcm' in href.lower():
                    dcm_match = re.search(r'dcm[_-]?no=(\d+)', href, re.IGNORECASE)
                    if dcm_match:
                        dcm_no = dcm_match.group(1)
                        print(f"  ë‹¤ìš´ë¡œë“œ ë§í¬ hrefì—ì„œ ë°œê²¬: {dcm_no}")
                        break
        
        print(f"\nğŸ“‹ ìµœì¢… íŒŒë¼ë¯¸í„°:")
        print(f"  rcpNo: {rcp_no}")
        print(f"  dcmNo: {dcm_no}")
        
        # ë‹¤ìš´ë¡œë“œ URL ìƒì„± ì‹œë„
        if rcp_no and dcm_no:
            download_url = f"https://dart.fss.or.kr/pdf/download/main.do?rcp_no={rcp_no}&dcm_no={dcm_no}"
            print(f"\nğŸ”— ì˜ˆìƒ ë‹¤ìš´ë¡œë“œ URL:")
            print(f"  {download_url}")
            
            # ë‹¤ìš´ë¡œë“œ URL í…ŒìŠ¤íŠ¸
            print(f"\nğŸ§ª ë‹¤ìš´ë¡œë“œ URL í…ŒìŠ¤íŠ¸:")
            try:
                dl_response = session.get(download_url, allow_redirects=True, stream=True)
                print(f"  ìƒíƒœ ì½”ë“œ: {dl_response.status_code}")
                print(f"  Content-Type: {dl_response.headers.get('Content-Type', 'ì—†ìŒ')}")
                print(f"  Content-Length: {dl_response.headers.get('Content-Length', 'ì—†ìŒ')}")
                
                if dl_response.status_code == 200 and 'application/pdf' in dl_response.headers.get('Content-Type', ''):
                    print(f"  âœ… PDF ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥!")
                    
                    # íŒŒì¼ëª… ì¶”ì¶œ
                    content_disposition = dl_response.headers.get('Content-Disposition', '')
                    if content_disposition:
                        filename_match = re.search(r'filename[*]?=["\']?([^"\';\s]+)', content_disposition)
                        if filename_match:
                            filename = filename_match.group(1)
                            print(f"  íŒŒì¼ëª…: {filename}")
                
            except Exception as e:
                print(f"  âŒ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        else:
            print(f"\nâŒ rcpNo ë˜ëŠ” dcmNoë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
        # í˜ì´ì§€ êµ¬ì¡° ê°„ë‹¨ ë¶„ì„
        print(f"\nğŸ“Š í˜ì´ì§€ êµ¬ì¡° ë¶„ì„:")
        title = soup.find('title')
        if title:
            print(f"  í˜ì´ì§€ ì œëª©: {title.get_text(strip=True)}")
        
        # ë‹¤ìš´ë¡œë“œ ê´€ë ¨ ìš”ì†Œë“¤ ì°¾ê¸°
        download_related = soup.find_all(string=re.compile(r'ë‹¤ìš´ë¡œë“œ|download|PDF|íŒŒì¼', re.IGNORECASE))
        print(f"  ë‹¤ìš´ë¡œë“œ ê´€ë ¨ í…ìŠ¤íŠ¸: {len(download_related)}ê°œ ë°œê²¬")
        for text in download_related[:3]:  # ì²˜ìŒ 3ê°œë§Œ
            print(f"    - '{text.strip()}'")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_report_page()