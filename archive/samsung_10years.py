#!/usr/bin/env python3
"""
ì‚¼ì„±ì „ì 10ë…„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
"""

from dart_scraper import DartScraper

def test_samsung_10years():
    """ì‚¼ì„±ì „ì 10ë…„ì¹˜ ê²€ìƒ‰"""
    print("ğŸ¯ ì‚¼ì„±ì „ì 10ë…„ì¹˜ DART ê²€ìƒ‰")
    print("=" * 50)
    
    scraper = DartScraper()
    
    if not scraper.get_search_page():
        print("âŒ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    print("âœ… DART ì‚¬ì´íŠ¸ ì ‘ì† ì„±ê³µ")
    
    # 10ë…„ ì „ì²´ ê²€ìƒ‰
    print("\nğŸ” 10ë…„ ì „ì²´ ê²€ìƒ‰")
    print("-" * 30)
    results_all = scraper.search_company("ì‚¼ì„±ì „ì", years=10, filter_reports=False, max_pages=10)
    
    if results_all:
        print(f"âœ… 10ë…„ ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {len(results_all)}ê±´")
        
        # ì—°ë„ë³„ ë¶„í¬ í™•ì¸
        year_counts = {}
        for result in results_all:
            submit_date = result.get('submit_date', '')
            if submit_date and len(submit_date) >= 4:
                year = submit_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        print("ì—°ë„ë³„ ë¶„í¬:")
        for year in sorted(year_counts.keys(), reverse=True):
            print(f"  {year}ë…„: {year_counts[year]}ê±´")
            
        print(f"\nìµœê·¼ 5ê±´:")
        for i, result in enumerate(results_all[:5], 1):
            print(f"  {i}. {result['report_name'][:40]}... ({result['submit_date']})")
    else:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return
    
    # 10ë…„ í•„í„°ë§ ê²€ìƒ‰
    print(f"\nğŸ” 10ë…„ í•„í„°ë§ ê²€ìƒ‰ (ë°˜ê¸°ë³´ê³ ì„œ, ë¶„ê¸°ë³´ê³ ì„œ, ì‚¬ì—…ë³´ê³ ì„œ)")
    print("-" * 30)
    results_filtered = scraper.search_company("ì‚¼ì„±ì „ì", years=10, filter_reports=True, max_pages=10)
    
    if results_filtered:
        print(f"âœ… í•„í„°ë§ ê²°ê³¼: {len(results_all)}ê±´ â†’ {len(results_filtered)}ê±´")
        
        # ë³´ê³ ì„œ íƒ€ì…ë³„ ë¶„í¬
        report_types = {}
        for result in results_filtered:
            report_name = result.get('report_name', '')
            if 'ë°˜ê¸°ë³´ê³ ì„œ' in report_name:
                report_types['ë°˜ê¸°ë³´ê³ ì„œ'] = report_types.get('ë°˜ê¸°ë³´ê³ ì„œ', 0) + 1
            elif 'ë¶„ê¸°ë³´ê³ ì„œ' in report_name:
                report_types['ë¶„ê¸°ë³´ê³ ì„œ'] = report_types.get('ë¶„ê¸°ë³´ê³ ì„œ', 0) + 1
            elif 'ì‚¬ì—…ë³´ê³ ì„œ' in report_name:
                report_types['ì‚¬ì—…ë³´ê³ ì„œ'] = report_types.get('ì‚¬ì—…ë³´ê³ ì„œ', 0) + 1
        
        print("ë³´ê³ ì„œ íƒ€ì…ë³„ ë¶„í¬:")
        for report_type, count in report_types.items():
            print(f"  {report_type}: {count}ê±´")
        
        print(f"\nëª¨ë“  í•„í„°ë§ëœ ë³´ê³ ì„œ:")
        for i, result in enumerate(results_filtered, 1):
            print(f"  {i:2d}. {result['report_name'][:50]}... ({result['submit_date']})")
            if result.get('report_url'):
                print(f"      ğŸ”— {result['report_url']}")
        
        # ë§í¬ íŒŒì¼ ì €ì¥
        print(f"\nğŸ’¾ ë§í¬ íŒŒì¼ ì €ì¥")
        print("-" * 30)
        scraper.save_links_to_txt(results_filtered, "samsung_10years_links.txt")
        
    else:
        print("âŒ í•„í„°ë§ ì¡°ê±´ì— ë§ëŠ” ë³´ê³ ì„œ ì—†ìŒ")


if __name__ == "__main__":
    test_samsung_10years()